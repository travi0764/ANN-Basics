{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxWPi0qVKfuL"
   },
   "source": [
    "## Multi-layer Perceptron\n",
    "\n",
    "\n",
    "The solution to fitting more complex (*i.e.* non-linear) models with neural networks is to use a more complex network that consists of more than just a single perceptron. The take-home message from the perceptron is that all of the learning happens by adapting the synapse weights until prediction is satisfactory. Hence, a reasonable guess at how to make a perceptron more complex is to simply **add more weights**.\n",
    "\n",
    "There are two ways to add complexity:\n",
    "\n",
    "1. Add backward connections, so that output neurons feed back to input nodes, resulting in a **recurrent network**\n",
    "2. Add neurons between the input nodes and the outputs, creating an additional (\"hidden\") layer to the network, resulting in a **multi-layer perceptron**\n",
    "\n",
    "The latter approach is more common in applications of neural networks.\n",
    "\n",
    "<a href=\"https://i.stack.imgur.com/n2Hde.png\">image source</a>\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/n2Hde.png\" width=50%>\n",
    "\n",
    "How to train a multilayer network is not intuitive. Propagating the inputs forward over two layers is straightforward, since the outputs from the hidden layer can be used as inputs for the output layer. However, the process for updating the weights based on the prediction error is less clear, since it is difficult to know whether to change the weights on the input layer or on the hidden layer in order to improve the prediction.\n",
    "\n",
    "Updating a multi-layer perceptron (MLP) is a matter of: \n",
    "\n",
    "1. moving forward through the network, calculating outputs given inputs and current weight estimates\n",
    "2. moving backward updating weights according to the resulting error from forward propagation. \n",
    "\n",
    "In this sense, it is similar to a single-layer perceptron, except it has to be done twice, once for each layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGeIe5StKfuO"
   },
   "source": [
    "## Backpropagation intiution\n",
    "\n",
    "* In the year 1986 a groundbreaking paper \"Learning Internal Representation by Error Propagation\" was published by -\n",
    "    * David Rumelhart,\n",
    "    * Geoffrey Hinton, &\n",
    "    * Ronald Williams \n",
    "    \n",
    "* It depicted an efficient way to update weights and biases of the network based on the error/loss function by passing twice through the network i.e forward and backward pass.\n",
    "    - forward pass: data is passed through the input layer to the hidden layer and it calculates ouput. Its nothing but making prediction.\n",
    "    - error calculation: Based on loss function error is calculated to check how much deviation is there from the ground truth or actual value and predicted value.\n",
    "    - error contribution from the each connection of the output layer is calculated.\n",
    "    - Then algo goes a layer deep and calculates how much previous layer contributed into the error of present layer and this way it propagates till the input layer.\n",
    "    - This reverse pass measures the error gradient accross all the connection.\n",
    "    - At last by using these error gradients a gradient step is performed to update the weights.\n",
    "    \n",
    "* In MLP key changes were to introduce a sigmoid activation function $$\\sigma(z) = \\frac{1}{1+e^{-z}}$$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Pa9h8TsKfuX"
   },
   "source": [
    "## Need of activation function\n",
    "\n",
    "* No activation function => deep stack of network will behave like a single linear transformation.\n",
    "* Without activation function all the continuous function cannot be approximated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 895
    },
    "id": "jYvrXPyEsSXx",
    "outputId": "c02ca290-03b2-4ba0-a00a-23c4ded74ffc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting HTMLrenderer\n",
      "  Using cached HTMLrenderer-0.1.6-py3-none-any.whl (7.6 kB)\n",
      "Collecting py-youtube==1.1.7\n",
      "  Using cached py_youtube-1.1.7-py3-none-any.whl (10 kB)\n",
      "Collecting ensure==1.0.2\n",
      "  Using cached ensure-1.0.2-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: six>=1.11.0 in /Users/ravitiwari/miniforge3/envs/tf/lib/python3.10/site-packages (from ensure==1.0.2->HTMLrenderer) (1.16.0)\n",
      "Installing collected packages: py-youtube, ensure, HTMLrenderer\n",
      "Successfully installed HTMLrenderer-0.1.6 ensure-1.0.2 py-youtube-1.1.7\n"
     ]
    }
   ],
   "source": [
    "!pip install HTMLrenderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gNzzXNF_KfuY"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'HTMLrenderer.render'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mHTMLrenderer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrender\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m render_site, render_HTML\n\u001b[1;32m      3\u001b[0m URL\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://slides.com/supremecommander/basic-neural-network/embed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m render_site(URL, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m100\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'HTMLrenderer.render'"
     ]
    }
   ],
   "source": [
    "from HTMLrenderer.render import render_site, render_HTML\n",
    "\n",
    "URL=\"https://slides.com/supremecommander/basic-neural-network/embed\"\n",
    "render_site(URL, width=\"100%\", height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iNeuron Notes --\n",
    "\n",
    "### why we use squashing activation functions ?? \n",
    "<b> Answer --> </b> ```If we don't use these functions, then output value can become very large either +ve or -ve, as there are lots of multiplications going on, and output may diverge to actual value. So to converge output value we use squashing activation functions.```\n",
    "\n",
    "    1) If we don't use activation functions then our complex deep neural network will behave like a single neuron.\n",
    "    \n",
    "    2) Activation functions are also used to bring non-linearity into neural networks, so that it can perform on complex structures also. Activation functions helps to gather important informations and drop non important informations. it helps to remember only important features and important informations.\n",
    "    \n",
    "    3) Total trainable parameters = first_layer*second_layer + bias = = 784*300 + 300(bias) = 235500\n",
    "    \n",
    "    4) Batch_size = number of samples per gradient update. So if we have total datapoints 55000 and have batch size 32 then, we will take 32 samples from 55000 datapoints, pass it through model and then update weights. so total steps would be 55000/32 = 1719. So for each step we will take sample of 32 and update weights. So weights will be updated total 1719 times in 1 epoch.\n",
    "    \n",
    "    5) np.reshape(X_train[10:30],(-1,28,28,1)) -1 ---> for 20 samples, it will take automatically take 20 as sample, it is extending the shape with 1. 28,28,1 ---> taking one sample of 28*28 B&W image.\n",
    "        \n",
    "    6) (-1,28,28,1) --> 1 is because there is only 1 channel B&W, if its coloured image then we can use 3 channels, RGB. 1 image consist of size*channel. so (size = 28*28) and channel = 1. So 1 image is (28*28*1). -1 is expanding its shape, -1 is used because it can be replaced. -1 is acting here just like dummy variable \"_\" in python.\n",
    "        \n",
    "    7) Patients level means if validation error or any other specified metrics is not increasing from last 5 (specified patients level) epochs, then it will stop training.\n",
    "    \n",
    "    8) model checkpoint callback is used to take backup of training model. we can start model training again if it crashes in middle. no need to start training it from scratch again. checkpoints remembers the best weights, it does not try to remember epochs informations. If model training is crashed say at epoch 11, then it will remember best weights from 1-10 epochs and if we start training again, then weights initialised will be best weights from last training and epoch will start from 1 again.\n",
    "    \n",
    "    9) By default tensorboard monitors validation loss, we can change it also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
